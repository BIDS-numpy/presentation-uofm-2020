{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# NumPy: A look at the past, present, and future of array computation\n",
    "\n",
    "Ross Barnowski `rossbar@berkeley.edu` | [rossbar](https://github.com/rossbar) on GitHub\n",
    "\n",
    "University of Michigan EECS | 1/30/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is NumPy?\n",
    "\n",
    "> *NumPy is the fundamental package for scientific computing with Python*\n",
    "> \n",
    ">  [numpy.org](https://numpy.org/)\n",
    "\n",
    "Strong stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The scientific Python ecosystem\n",
    "\n",
    "![scientific_python_ecosystem](images/state_of_the_stack_2015.png)\n",
    "\n",
    "Image credit: [Jake VanderPlas](http://vanderplas.com/) circa 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Code example: github graphql query for top starred projects with numpy as a dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# At a glance\n",
    "\n",
    "![numpy_overview](images/numpy_overview_graphic.png)\n",
    "\n",
    "Image credit: [Shaloo Shalini](https://www.linkedin.com/in/shalooshalini/): [@shaloo](https://github.com/shaloo) on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A bit of history\n",
    "\n",
    " - **Mid 90's/Early 00's**: desire for high-performance numerical computation in python eventually culminates in the [`Numeric`](https://numpy.org/_downloads/768fa66c250a0335ad3a6a30fae48e34/numeric-manual.pdf) library\n",
    " - Early adopters included the [Space Telescope Science Institute (STScI)](http://www.stsci.edu/) who developed another array computation package to better suit their needs: `Numarray`.\n",
    " - **2005** The best ideas from `Numeric` and `Numarray` were combined in the development of a new library, `numpy`\n",
    "   * This work was largely done by [Travis Oliphant](https://github.com/teoliphant), then an assistant professor at BYU\n",
    " - **2006** Numpy v1.0 released in October\n",
    " \n",
    "[NumPy Development History](https://github.com/numpy/numpy/graphs/contributors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What does NumPy provide?\n",
    "\n",
    " - `ndarray`: A generic, n-dimensional array data structure\n",
    " - Sophisticated machinery for operating on array data (vectorization, broadcasting, `ufuncs`)\n",
    " - Language extension/integration (C-API, `f2py`)\n",
    "   * [Array API](https://numpy.org/doc/1.17/reference/c-api.array.html) for accessing/extending array functionality in external libraries\n",
    " - Protocols for mimicing the very successful NumPy Python interfaces for other easey interoperability with other packages (more later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What else?\n",
    "\n",
    "For historical reasons, `numpy` also includes tools for common scientific/numerical tasks:\n",
    "   * Random number generation (`np.random`)\n",
    "   * Fourier analysis (`np.fft`)\n",
    "   * Linear algebra (`np.linalg`)\n",
    "   * Manipulating finite power series (`np.polynomial`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The `scipy` package includes modules with the same name? What's the deal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import scipy, scipy.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(scipy.random)\n",
    "scipy.random is np.random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(scipy.fft)\n",
    "scipy.fft is np.fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(scipy.linalg)\n",
    "scipy.linalg is np.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<font color=\"red\">Check with team</font>\n",
    "\n",
    "NumPy will continue to *support* the `fft` and `linalg` modules, but the scipy versions should probably preferred for new code:\n",
    " - Optimizations/enhancements\n",
    " - More capabilities: e.g. see [this quick comparison](https://numpy.org/devdocs/reference/routines.linalg.html) of the `numpy` and `scipy` `linalg` modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where is NumPy used?\n",
    "\n",
    "### <font color=red> Investigate the following for appropriately sized examples </font>\n",
    "\n",
    " - To produce the first image of a black hole \n",
    "   [Event Horizon Telescope Collaboration](https://github.com/achael/eht-imaging)\n",
    " - [To detect the gravitational wave signature from a neutron star merger](https://github.com/gwastro/pycbc)\n",
    " - [To discover fundamental particles like the Higgs Boson](https://github.com/cms-sw/cmssw)\n",
    "   * Also [scikit-hep](https://scikit-hep.org/)\n",
    " - [Neuroimaging](https://nipy.org/nibabel/) - nipy uses `ndarray` as the fundamental structure for the entire stack\n",
    "   * fMRI visualization example from [section 3.4](https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/full#h4)\n",
    "     is a nice, brief example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Neuroimaging Analysis\n",
    "\n",
    "Like much of the scientific python ecosystem, the [nipy organization](https://nipy.org/) relies on `np.ndarray` as the fundamental structure for neuroimaging data\n",
    "\n",
    "The following example is adapted from [Machine learning for neuroimaging with scikit learn](https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/full). The dataset used comes from the [nilearn data](https://www.nitrc.org/frs/?group_id=728).\n",
    "\n",
    "<font color=red>**Add example of loading full Nifti image to show 4D structure of data?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import nibabel   # package for loading/saving neuroimaging data\n",
    "bg_img = nibabel.load('data/bg.nii.gz')\n",
    "bg = bg_img.get_fdata()\n",
    "type(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create activation map by thresholding the data\n",
    "act_thresh = 6000\n",
    "act = bg.copy()\n",
    "# Set \"unactivated\" voxels to NaN for visualization\n",
    "act[act <= act_thresh] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# imshow kwargs\n",
    "imshow_opts = {\n",
    "    \"origin\" : \"lower\",\n",
    "    \"interpolation\" : \"nearest\"\n",
    "}\n",
    "\n",
    "# Axial slice of activation map overlay\n",
    "plt.imshow(bg[...,10].T, cmap=\"gray\");             # Background\n",
    "plt.imshow(act[...,10].T, cmap=\"plasma\");          # Activation map\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Detecting gravitational wave signature of black hole and neutron star mergers\n",
    "\n",
    "[PyCBC](https://pycbc.org/) is the toolkit used to analyze data from gravitational wave observatories like [LIGO](https://www.ligo.caltech.edu/) and [Virgo](http://www.virgo-gw.eu/).\n",
    "\n",
    "The [PyCBC tutorials](https://github.com/gwastro/PyCBC-Tutorials) have some really cool examples - let's recreate the \"chirp\" from [first ever direct detection of gravitational waves](https://en.wikipedia.org/wiki/First_observation_of_gravitational_waves) that resulted from two black holes merging. For more info, see [the second PyCBC tutorial](https://colab.research.google.com/github/gwastro/pycbc-tutorials/blob/master/tutorial/2_VisualizationSignalProcessing.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pycbc\n",
    "from pycbc import catalog\n",
    "\n",
    "merger_data = catalog.Merger('GW150914')\n",
    "# Though the catalog includes data from multiple observatories,\n",
    "# let's focus on just one\n",
    "ligo_data = merger_data.strain('L1')\n",
    "type(ligo_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pycbc` has its own (quite extensive) API that uses `numpy` and `scipy` under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(type(ligo_data._data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pycbc.types.aligned.ArrayWithAligned.__bases__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To re-create the \"chirp\" we have to do some analysis on the raw data. `pycbc` relies on tools in `scipy.fft` and `scipy.signal` to implement the frequency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Flatten frequency \n",
    "res = ligo_data.whiten(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "time_of_merger = merger_data.time\n",
    "\n",
    "# Look 100 msec-worth of data around the merger time\n",
    "roi = res.time_slice(time_of_merger - 0.1, time_of_merger + 0.1)\n",
    "\n",
    "# Similar to a spectrogram with more sophisticated, irregular sampling\n",
    "times, freqs, power = roi.qtransform(\n",
    "    delta_t=0.001,\n",
    "    logfsteps=100,\n",
    "    qrange=(8, 8),\n",
    "    frange=(30, 512),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "ax.pcolormesh(times, freqs, power**0.5)\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scope of NumPy\n",
    "\n",
    "NumPy currently targets computation involving:\n",
    "\n",
    " * in-memory, homogenously-typed array data\n",
    " * cpu-based\n",
    " \n",
    "but provides protocols to allow developers of packages targeting other computational models hooks to seamlessly interoperate in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Important guiding principles:\n",
    " - **Stability**: Foundational component of the scientific python ecosystem for going-on 15 years\n",
    " - **Interoperability**\n",
    "   * NumPy is the standard array data structure within the scientific Python ecosystem\n",
    "   * What about all the new array libraries?\n",
    "     - [XArray](http://xarray.pydata.org/en/stable/)\n",
    "     - [Dask Arrays](https://docs.dask.org/en/latest/array.html)\n",
    "     - [Jax](https://jax.readthedocs.io/en/latest/)\n",
    "     - [pydata sparse](https://sparse.pydata.org/en/latest/)\n",
    "     - [PyTorch](https://pytorch.org/)\n",
    "     - [TensorFlow](https://www.tensorflow.org/api_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The changing landscape\n",
    "\n",
    " - In the early days, many new NumPy users were converts from languages like Matlab and IDL\n",
    "   * See the [NumPy for Matlab users](https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html) article in the docs\n",
    "   \n",
    " - **Now**: The scientific Python ecosystem (including libraries for data science and ML) is incredibly feature-rich and powerful, and is attracting many new users.\n",
    "   * Users interested in specific applications (machine learning, image processing, geoscience, bioinformatics, etc.) end up interacting with NumPy indirectly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Google Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Data downloaded from google trends\n",
    "!ls data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!head data/datascience.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "timeseries_dtype = np.dtype([\n",
    "    ('date', 'datetime64[M]'),\n",
    "    ('relpop', float)\n",
    "])\n",
    "\n",
    "parse_kwargs = {\n",
    "    \"skiprows\" : 3,\n",
    "    \"delimiter\" : \",\",\n",
    "    \"dtype\" : timeseries_dtype\n",
    "}\n",
    "\n",
    "fnames = (\"numpy\", \"datascience\", \"matlab\")\n",
    "\n",
    "data = {\n",
    "    fname : np.loadtxt(\"data/{}.csv\".format(fname), **parse_kwargs) for fname in fnames\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for name, vals in data.items():\n",
    "    plt.plot(vals['date'], vals['relpop'], label=name)\n",
    "ax.set_title('Google Trends (US): 2004 - Present')\n",
    "ax.set_ylabel('Relative Popularity of Search Term [arb]')\n",
    "fig.autofmt_xdate()\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def smooth(s, kernsize=21):\n",
    "    s_padded = np.r_[s[kernsize-1:0:-1], s, s[-2:-kernsize-1:-1]]\n",
    "    kern = np.hamming(kernsize)\n",
    "    res_padded = np.convolve(kern/kern.sum(), s_padded, mode='valid')\n",
    "    # De-pad and renormalize\n",
    "    return 100 * res_padded[kernsize//2:-kernsize//2+1] / res_padded.max()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, vals in data.items():\n",
    "    plt.plot(vals['date'], smooth(vals['relpop']), label=name)\n",
    "ax.set_title('Google Trends (US): 2004 - Present')\n",
    "ax.set_ylabel('Relative Popularity of Search Term [arb]')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The changing landscape \n",
    " * Focus resources on supporting stable, performant base for dependent libraries\n",
    "   * Scope: what goes in NumPy itself vs. dependent packages?\n",
    "   * Balance between performance and maintainability\n",
    "     > Optimization is the altar where maintainability is sacrificed\n",
    "     >\n",
    "     > \\- Luciano Ramalho, *Fluent Python*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How is NumPy Developed\n",
    "\n",
    " - Collaboratively <font color=\"red\">(caveat here about the bus factor?)</font>\n",
    "\n",
    "Commitment to stability means proposed changes must go through extensive design and review:\n",
    " - [Numpy Enhancement Proposals (NEPs)](https://numpy.org/neps/) - analogous to PEPs, specific to NumPy\n",
    " - Steering council for high-level direction and coordination with [NumFOCUS](https://numfocus.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Case-Study: `np.random`\n",
    " - Changes proposed in [NEP 19](https://numpy.org/neps/nep-0019-rng-policy.html), subsequently approved by the community after discussion on the mailing list and issue tracker. The changes all include tests and benchmarks.\n",
    " - Overhaul of `np.random` landed in version 1.17\n",
    " \n",
    "   * Improve *performance* and *flexibility* without sacrificing stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Generate 1,000,000 random numbers the old way\n",
    "old_rands = np.random.random(int(1e6))\n",
    "print(\"Uniform random numbers from legacy np.random.random:\\n  {}\".format(old_rands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# ... and the new way\n",
    "from numpy.random import PCG64, Generator\n",
    "rg = Generator(PCG64())\n",
    "new_rands = rg.random(int(1e6))\n",
    "print(\"Uniform random numbers with new tools:\\n  {}\".format(new_rands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compatibility\n",
    "\n",
    "Before version 1.17, `numpy.random` relied on `RandomState` to configure and produce random numbers.\n",
    "\n",
    "There are many, many LOC (both in test suites and in production) that depend on the original `numpy.random`, so both the *interface* and the *results* must remain unchanged. This is enforced via testing.\n",
    " * <font color=\"green\">**Upside: Stability**</font> - output of `np.random` remains consistent with previous versions\n",
    " * <font color=\"orange\">**Downside: Discoverability**</font> - users need to know about new interface to access improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Choose a seed for generator\n",
    "seed = 1817\n",
    "\n",
    "# Random numbers generated by np.random in v1.15\n",
    "rands_from_v1_15 = np.load('data/npy_v1.15_random_seed1817_1000samples.npy')\n",
    "# Generate random numbers with legacy interface\n",
    "np.random.seed(seed)\n",
    "legacy_rands = np.random.random(1000)\n",
    "\n",
    "print(\"Arrays equivalent: \", np.allclose(rands_from_v1_15, legacy_rands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is possible (though clunky) to replicate legacy behavior with new interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "seed = 1817\n",
    "\n",
    "from numpy.random import MT19937, RandomState\n",
    "# Set random state with legacy seeding\n",
    "rs = RandomState(seed)\n",
    "mt = MT19937()\n",
    "mt.state = rs.get_state()\n",
    "\n",
    "# New interface for generation\n",
    "rg = Generator(mt)\n",
    "mt_rands = rg.random(1000)\n",
    "print(\"Legacy: {}\\nGenerator: {}\".format(legacy_rands[:4], mt_rands[:4]))\n",
    "print(\"Arrays equivalent: \", np.allclose(legacy_rands, mt_rands))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Performance\n",
    "\n",
    "The [PCG64](https://docs.scipy.org/doc/numpy/reference/random/bit_generators/pcg64.html) BitGenerator is a \n",
    "[significant improvment](http://www.pcg-random.org/) over the legacy Marsenne Twister in many areas, including speed:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#NOTE: PCG64 is the new default bit_generator, so default_rng() equivalent to Generator(PCG64())\n",
    "from numpy.random import default_rng\n",
    "rg = default_rng()\n",
    "num_samples = int(1e5)\n",
    "\n",
    "print(\"Uniform random numbers:\")\n",
    "%timeit np.random.random(num_samples)\n",
    "%timeit rg.random(num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In addition, `Generator` includes improved methods for drawing samples from distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Standard Normal:\")\n",
    "%timeit np.random.standard_normal(num_samples)\n",
    "%timeit rg.standard_normal(num_samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Standard Exponential:\")\n",
    "%timeit np.random.standard_exponential(num_samples)\n",
    "%timeit rg.standard_exponential(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Standard Gamma:\")\n",
    "shape_param = 3.0\n",
    "%timeit np.random.standard_gamma(shape_param, num_samples)\n",
    "%timeit rg.standard_gamma(shape_param, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What's next for NumPy?\n",
    "\n",
    "![NumpyRoadmapGraphic](./images/numpy_roadmap_graphic.png)\n",
    "\n",
    "Image from [this PyData Amsterdam 2019 presentation](https://www.slideshare.net/RalfGommers/the-evolution-of-array-computing-in-python/14) by [Ralf Gommers](https://github.com/rgommers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interoperability\n",
    "\n",
    "Separate NumPy API from NumPy \"execution engine\"\n",
    " - Allow other libraries ([Dask](https://dask.org/), [CuPy](https://cupy.chainer.org/), [PyTorch](https://pytorch.org/)) to reuse NumPy API\n",
    " - Mitigate ecosystem fragmentation\n",
    "   * E.g. don't want a re-implementation of `scipy` for each ML framework (`pytorch.scipy`, `tensorflow.scipy`, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Current n-dimensional array landscape\n",
    "\n",
    "![arrays_now](images/array_landscape_now.png)\n",
    "\n",
    "Images from this [talk at PyData NY 2019](https://www.slideshare.net/RalfGommers/pydata-nyc-whatsnew-numpyscipy-2019?next_slideshow=1) by [Ralf Gommers](https://github.com/rgommers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Vision for the future\n",
    "\n",
    "![array_vision](images/array_landscape_vision.png)\n",
    "\n",
    "Images from this [talk at PyData NY 2019](https://www.slideshare.net/RalfGommers/pydata-nyc-whatsnew-numpyscipy-2019?next_slideshow=1) by [Ralf Gommers](https://github.com/rgommers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## First solution: `__array_function__` protocol\n",
    "\n",
    " - Proposed in [NEP 18](https://numpy.org/neps/nep-0018-array-function-protocol.html)\n",
    " - Array function protocol enabled by default as of version 1.17\n",
    " \n",
    "![array_function_protocol](images/array_function_descr.png)\n",
    " \n",
    "Image source: [this presentation](https://www.slideshare.net/RalfGommers/arrayfunction-conceptual-design-related-concepts?from_action=save) by [Ralf Gommers](https://github.com/rgommers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### `__array_function__` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rg = np.random.default_rng()\n",
    "x = rg.random((5000, 1000))\n",
    "\n",
    "# Factorize with np.linalg\n",
    "q, r = np.linalg.qr(x)\n",
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "\n",
    "d = da.from_array(x, chunks=(1000, 1000))\n",
    "\n",
    "# Same call signature!\n",
    "q, r = np.linalg.qr(d)\n",
    "type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "da.core.Array??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lessons learned from `__array_function__`\n",
    "\n",
    " - The `__array_function__` protocol has been partially successful, but has fallen short of universal adoption.\n",
    " - Valuable feedback from the community has resulted in [NEP 37](https://numpy.org/neps/nep-0037-array-module.html)\n",
    "   * Defines `__array_module__` protocol\n",
    "   * Currently under development (interested?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Overhaul of the data type system\n",
    "\n",
    "NumPy relies on dtypes to describe how to interpret array elements. In principal, the NumPy C-API allows for user-defined dtypes, but some components of the dtype machinery (e.g. some logic for casting rules) is not extensible by user-defined types.\n",
    "\n",
    "A [NEP is currently being drafted](https://github.com/numpy/numpy/blob/a111b551ae940d7d5f8523fef1cf3589c6ba00a0/doc/neps/nep-0033-extensible-dtypes.rst) to improve the extensibility of the dtype system. Some of the impetus for this work comes from the ML community, such as the desire for `bfloat16` and categorical types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Improved SIMD incorporation for `ufuncs`\n",
    "\n",
    "Strike a balance between **optimization** and **maintainability**\n",
    "\n",
    " - Define set of architecture-agnostic universal intrinsics\n",
    "   * At build time, build code paths based on features available for the host architecture\n",
    "   * At run time, detect which features are available and select which of available code paths to use\n",
    " - In the process of being formalized in a [draft NEP](https://github.com/numpy/numpy/blob/7904b1a6e43d2dc2bbdab8e7fda03ad44bd60ca1/doc/neps/nep-0038-SIMD-optimizations.rst)\n",
    "   * Preliminary work in support of this proposed enhancment can be found [here](https://github.com/numpy/numpy/pull/13421/files) and [here](https://github.com/numpy/numpy/pull/13516)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Slides on indexing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supporting language features: type annotations\n",
    "\n",
    "Thinking about how best to support type annotations became especially important when they became an official core language feature in Python 3.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Work on type annotations is located in the [numpy-stubs](https://github.com/numpy/numpy-stubs) repository. Basic type annotations are supported. Here's the contents of `type_annotations.py`:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def my_strict_sin(x: np.ndarray) -> np.ndarray:\n",
    "    return np.sin(x)\n",
    "\n",
    "def my_chill_sin(x: np.array_like) -> np.array_like:\n",
    "    return np.sin(x)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    a = np.arange(10)\n",
    "    l = [1, 2, 3]\n",
    "    my_strict_sin(a)     # Passes typecheck\n",
    "    my_strict_sin(l)     # Fails typecheck\n",
    "    my_chill_sin(a)      # Passes typecheck\n",
    "    my_chill_sin(l)      # Passes typecheck\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!mypy type_annotations.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Beyond the horizon... NumPy 2.0?\n",
    "\n",
    " - Major revision -> opportunity for refactoring/enhancements that break API\n",
    "   * Weigh potential for improvements against the pain of breaking changes (example: Python2 -> Python3)\n",
    " - So much new functionality being developed in external libraries\n",
    "   * Changes that facilitate external development are priorities\n",
    " \n",
    "A bit of the history surrounding the idea of NumPy 2.0 can be found [here](https://github.com/numpy/numpy/issues/9066)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting involved\n",
    "\n",
    "NumPy presents an opportunity to work on a project that is depended on by tens of millions of users (and counting). Here's how you can get involved:\n",
    " 1. Contribute\n",
    "   - [GitHub Issues](https://github.com/numpy/numpy/issues) and [open PRs](https://github.com/numpy/numpy/pulls) are a great entry point\n",
    "     * If you want to get your hands dirty immediately, try starting with the [good first issue](https://github.com/numpy/numpy/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) label\n",
    "     * For challenges with a greater scope, try the [Enhancement](https://github.com/numpy/numpy/labels/01%20-%20Enhancement) or [Wish List](https://github.com/numpy/numpy/labels/23%20-%20Wish%20List) labels\n",
    "   - Check out the discussion revolving around accepted and proposed [NEPs](https://numpy.org/neps/)\n",
    " 2. Participate in the conversation\n",
    "  - [Numpy discussion mailing list](https://www.scipy.org/scipylib/mailing-lists.html)\n",
    "  - Numpy [community meetings](https://github.com/numpy/archive/tree/master/status_meetings) (links and cadence here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
